name: PULSE CI

on:
  push:
    branches: [main]
    tags:
      - "v*"
      - "V*"
    paths-ignore:
      - "docs/**"
      - "**/*.md"
      - "badges/**"
      - "reports/**"
      - "!docs/policy/CHANGELOG.md"

  pull_request:
    branches: [main]

  workflow_dispatch:
    inputs:
      strict_external_evidence:
        description: "Require external *_summary.json evidence (fail if missing)"
        required: false
        default: "false"
        type: choice
        options:
          - "false"
          - "true"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

# Least privilege by default: this workflow must not write to the repo.
permissions:
  contents: read

jobs:
  pulse:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # pinned
        with:
          fetch-depth: 0
          persist-credentials: false

      - name: Enforce changelog for policy/spec changes
        shell: bash
        run: |
          set -euo pipefail

          # Determine diff range depending on event type.
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            BASE="${{ github.event.pull_request.base.sha }}"
            HEAD="${{ github.event.pull_request.head.sha }}"
          elif [[ "${{ github.event_name }}" == "push" ]]; then
            BASE="${{ github.event.before }}"
            HEAD="${{ github.sha }}"
          else
            echo "Skipping changelog enforcement: unsupported event '${{ github.event_name }}'."
            exit 0
          fi

          # Handle edge cases (e.g., first commit or unusual events).
          if [[ -z "${BASE}" || "${BASE}" == "0000000000000000000000000000000000000000" ]]; then
            echo "Skipping changelog enforcement: BASE SHA is empty/zero."
            exit 0
          fi

          echo "Changelog enforcement diff range: ${BASE}..${HEAD}"

          CHANGED="$(git diff --name-only "${BASE}" "${HEAD}" || true)"
          echo "${CHANGED}" | sed 's/^/changed: /' || true

          # Files that can change release-gating meaning and therefore require changelog coverage.
          SEMANTIC_PATTERN='^(pulse_gate_policy_v0\.yml|metrics/specs/|schemas/dataset_manifest\.schema\.json|examples/dataset_manifest\.example\.json)'

          # Changelog file containing semantic change notes.
          CHANGELOG_PATH='docs/policy/CHANGELOG.md'

          # If nothing semantic changed, do nothing.
          SEMANTIC_CHANGED="$(echo "${CHANGED}" | grep -E "${SEMANTIC_PATTERN}" || true)"
          if [[ -z "${SEMANTIC_CHANGED}" ]]; then
            echo "No semantic policy/spec/contract changes detected; changelog update not required."
            exit 0
          fi

          if [[ ! -f "${CHANGELOG_PATH}" ]]; then
            echo "::error::Changelog not found at ${CHANGELOG_PATH}."
            exit 1
          fi

          export SEMANTIC_CHANGED
          export CHANGELOG_PATH

          python3 - <<'PY'
          import os, re, sys
          from pathlib import Path

          changed = [ln.strip() for ln in os.environ["SEMANTIC_CHANGED"].splitlines() if ln.strip()]
          changelog_path = Path(os.environ["CHANGELOG_PATH"])
          text = changelog_path.read_text(encoding="utf-8", errors="replace")

          # Accept both "## Unreleased" and "## [Unreleased]" (robust, not brittle).
          m = re.search(r"^##\s*\[?\s*Unreleased\s*\]?\s*$([\s\S]*?)(?=^##\s+\S|\Z)", text, flags=re.M | re.I)
          if not m:
            print("::error::docs/policy/CHANGELOG.md is missing an 'Unreleased' section (expected '## Unreleased' or '## [Unreleased]').")
            sys.exit(1)

          unrel = m.group(1)
          unrel_l = unrel.lower()

          def stem_variants(stem: str):
            s = stem.lower()
            s2 = re.sub(r"_v\d+$", "", s)  # drop _v0 suffix (q3_fairness_v0 -> q3_fairness)
            return {
              s,
              s2,
              s2.replace("_", " "),
              s2.replace("_", "-"),
            }

          def parse_spec_id_version(path: Path):
            # Minimal YAML parsing for the spec block: look for top-level "spec:" then id/version inside.
            in_spec = False
            spec_id = None
            spec_ver = None

            for raw in path.read_text(encoding="utf-8", errors="replace").splitlines():
              line = raw.rstrip("\n")

              # enter spec block on exact top-level "spec:"
              if not in_spec and re.match(r"^spec:\s*$", line):
                in_spec = True
                continue

              if in_spec:
                # leaving spec block when another top-level key starts (non-empty and no leading spaces)
                if re.match(r"^[A-Za-z0-9_]+\s*:\s*$", line) and not line.startswith(" "):
                  break

                # capture id and version lines inside spec
                m_id = re.match(r"^\s*id:\s*(.+?)\s*$", line)
                if m_id and spec_id is None:
                  spec_id = m_id.group(1).strip().strip('"').strip("'")
                  continue

                m_ver = re.match(r"^\s*version:\s*(.+?)\s*$", line)
                if m_ver and spec_ver is None:
                  spec_ver = m_ver.group(1).strip().strip('"').strip("'")
                  continue

                if spec_id and spec_ver:
                  break

            return spec_id, spec_ver

          def parse_policy_id_version(path: Path):
            # Minimal YAML parsing for the policy block: look for top-level "policy:" then id/version inside.
            in_policy = False
            pol_id = None
            pol_ver = None

            for raw in path.read_text(encoding="utf-8", errors="replace").splitlines():
              line = raw.rstrip("\n")

              # enter policy block on exact top-level "policy:"
              if not in_policy and re.match(r"^policy:\s*$", line):
                in_policy = True
                continue

              if in_policy:
                # leaving policy block when another top-level key starts (non-empty and no leading spaces)
                if re.match(r"^[A-Za-z0-9_]+\s*:\s*$", line) and not line.startswith(" "):
                  break

                m_id = re.match(r"^\s*id:\s*(.+?)\s*$", line)
                if m_id and pol_id is None:
                  pol_id = m_id.group(1).strip().strip('"').strip("'")
                  continue

                m_ver = re.match(r"^\s*version:\s*(.+?)\s*$", line)
                if m_ver and pol_ver is None:
                  pol_ver = m_ver.group(1).strip().strip('"').strip("'")
                  continue

                if pol_id and pol_ver:
                  break

            return pol_id, pol_ver

          missing = []

          for p in changed:
            if p.startswith("metrics/specs/") and p.endswith(".yml"):
              spec_path = Path(p)
              if not spec_path.exists():
                missing.append((p, "spec file missing in workspace"))
                continue

              spec_id, spec_ver = parse_spec_id_version(spec_path)

              # Fallbacks: use filename stem if spec.id missing (but warn via error).
              file_stem = spec_path.stem.lower()
              want_any = set()

              if spec_id:
                want_any |= stem_variants(spec_id)
              else:
                want_any |= stem_variants(file_stem)

              # Require at least one identifier token AND the version string to appear in Unreleased.
              id_ok = any(tok and tok in unrel_l for tok in want_any)
              ver_ok = (spec_ver is not None) and (str(spec_ver).strip() in unrel)

              if not id_ok or not ver_ok:
                reason = []
                if not id_ok:
                  reason.append(f"missing id token (expected one of: {sorted(want_any)})")
                if spec_ver is None:
                  reason.append("missing spec.version in file")
                elif not ver_ok:
                  reason.append(f"missing version '{spec_ver}' in Unreleased")
                missing.append((p, "; ".join(reason)))
            elif p == "pulse_gate_policy_v0.yml":
              pol_path = Path(p)
              if not pol_path.exists():
                missing.append((p, "policy file missing in workspace"))
                continue

              pol_id, pol_ver = parse_policy_id_version(pol_path)

              if pol_id is None:
                # fallback to file stem
                pol_id = pol_path.stem
              want_any = stem_variants(pol_id)

              id_ok = any(tok and tok in unrel_l for tok in want_any)
              ver_ok = (pol_ver is not None) and (str(pol_ver).strip() in unrel)

              if not id_ok or not ver_ok:
                reason = []
                if not id_ok:
                  reason.append(f"missing policy id token (expected one of: {sorted(want_any)})")
                if pol_ver is None:
                  reason.append("missing policy.version in file")
                elif not ver_ok:
                  reason.append(f"missing version '{pol_ver}' in Unreleased")
                missing.append((p, "; ".join(reason)))
            elif p in ("schemas/dataset_manifest.schema.json", "examples/dataset_manifest.example.json"):
              key = Path(p).stem.replace(".", " ").replace("_", " ").lower()
              if key not in unrel_l:
                missing.append((p, f"missing '{key}' mention in Unreleased"))

          if missing:
            print("::error::Changelog is missing required Unreleased notes for semantic changes:")
            for p, reason in missing:
              print(f"  - {p}: {reason}")
            sys.exit(1)

          print("Changelog enforcement: OK")
          PY

      - name: Install system deps
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq

      - name: Set up Python
        uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 # pinned
        with:
          python-version: "3.11"

      - name: Set up deps
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt

      - name: Print python version
        shell: bash
        run: |
          set -euo pipefail
          python --version
          python -c "import sys; print(sys.executable)"

      - name: Run lint
        shell: bash
        run: |
          set -euo pipefail
          python -m ruff check .

      - name: Run tests
        shell: bash
        run: |
          set -euo pipefail
          python -m pytest -q

      - name: Run gate-level checks
        shell: bash
        run: |
          set -euo pipefail
          # if this is a workflow dispatch run and strict_external_evidence is true, fail
          if [[ "${{ github.event_name }}" == "workflow_dispatch" && "${{ github.event.inputs.strict_external_evidence }}" == "true" ]]; then
            python tools/validate_strict_external_evidence.py
          else
            python tools/validate_external_evidence.py --allow-missing
          fi
          python tools/validate_release_gates.py --policy pulse_gate_policy_v0.yml --status tests/fixtures/quick_status.json

      - name: Export PULSE status.json (snapshot)
        shell: bash
        run: |
          set -euo pipefail
          python tools/export_status.py --status tests/fixtures/quick_status.json

      - name: Export PULSE status.json with detailed metadata (snapshot)
        shell: bash
        run: |
          set -euo pipefail
          python tools/export_status.py --status tests/fixtures/quick_status.json --detailed-metadata

      - name: Export PULSE status.json with external evidence (snapshot)
        shell: bash
        run: |
          set -euo pipefail
          python tools/export_status.py --status tests/fixtures/quick_status.json --external-evidence

      - name: Validate PULSE status.json schema
        shell: bash
        run: |
          set -euo pipefail
          python tools/validate_status_schema.py --status tests/fixtures/quick_status.json

      - name: Validate status.json schema with detailed metadata
        shell: bash
        run: |
          set -euo pipefail
          python tools/validate_status_schema.py --status tests/fixtures/quick_status.json --detailed-metadata

      - name: Validate status.json schema with external evidence
        shell: bash
        run: |
          set -euo pipefail
          python tools/validate_status_schema.py --status tests/fixtures/quick_status.json --external-evidence

      - name: Validate status.json schema by JSON schema
        shell: bash
        run: |
          set -euo pipefail
          python tools/validate_status_schema.py --status tests/fixtures/quick_status.json --json-schema-only

      - name: Validate status.json schema by JSON schema (detailed metadata)
        shell: bash
        run: |
          set -euo pipefail
          python tools/validate_status_schema.py --status tests/fixtures/quick_status.json --detailed-metadata --json-schema-only

      - name: Validate status.json schema by JSON schema (external evidence)
        shell: bash
        run: |
          set -euo pipefail
          python tools/validate_status_schema.py --status tests/fixtures/quick_status.json --external-evidence --json-schema-only

      - name: Validate report schema
        shell: bash
        run: |
          set -euo pipefail
          python tools/validate_report_schema.py --report tests/fixtures/quick_report.json

      - name: Validate status.json plus report schema
        shell: bash
        run: |
          set -euo pipefail
          python tools/validate_report_schema.py --report tests/fixtures/quick_report.json --status tests/fixtures/quick_status.json

      - name: Build PULSE report
        shell: bash
        run: |
          set -euo pipefail
          python tools/build_report.py --status tests/fixtures/quick_status.json --report tests/fixtures/quick_report.json

      - name: Build PULSE report (detailed metadata)
        shell: bash
        run: |
          set -euo pipefail
          python tools/build_report.py --status tests/fixtures/quick_status.json --report tests/fixtures/quick_report.json --detailed-metadata

      - name: Build PULSE report (external evidence)
        shell: bash
        run: |
          set -euo pipefail
          python tools/build_report.py --status tests/fixtures/quick_status.json --report tests/fixtures/quick_report.json --external-evidence

      - name: Compute overlays
        shell: bash
        run: |
          set -euo pipefail
          python tools/compute_field_v0.py --status tests/fixtures/quick_status.json
          python tools/compute_field_stability_v0.py --status tests/fixtures/quick_status.json
          python tools/compute_epf_overlay_v0.py --status tests/fixtures/quick_status.json
          python tools/compute_separation_phase_overlay_v0.py --status tests/fixtures/quick_status.json

      - name: Generate PULSE snapshot report (HTML)
        shell: bash
        run: |
          set -euo pipefail
          python tools/status_to_html_snapshot.py --status tests/fixtures/quick_status.json

      - name: Generate PULSE snapshot report (Markdown)
        shell: bash
        run: |
          set -euo pipefail
          python tools/status_to_md_snapshot.py --status tests/fixtures/quick_status.json

      - name: Write PULSE summary
        shell: bash
        run: |
          set -euo pipefail
          python tools/write_pulse_summary.py --status tests/fixtures/quick_status.json

      - name: Prepare overlay outputs
        shell: bash
        run: |
          set -euo pipefail

          OVERLAY_DIR="artifacts/overlay"
          mkdir -p "$OVERLAY_DIR"

          copy_if_exists () {
            local src="$1"
            local dst="$2"
            if [ -f "$src" ]; then
              cp "$src" "$dst"
            else
              echo "::warning::missing overlay artifact: $src"
            fi
          }

          copy_if_exists "artifacts/stability_map_v0.json" "$OVERLAY_DIR/stability_map_v0.json"
          copy_if_exists "artifacts/stability_map_v0.md" "$OVERLAY_DIR/stability_map_v0.md"
          copy_if_exists "artifacts/stability_map_v0.svg" "$OVERLAY_DIR/stability_map_v0.svg"

          copy_if_exists "artifacts/field_stability_v0.json" "$OVERLAY_DIR/field_stability_v0.json"
          copy_if_exists "artifacts/field_stability_v0.md" "$OVERLAY_DIR/field_stability_v0.md"

          copy_if_exists "artifacts/field_v0.json" "$OVERLAY_DIR/field_v0.json"
          copy_if_exists "artifacts/field_v0.md" "$OVERLAY_DIR/field_v0.md"

          copy_if_exists "artifacts/g_epf_overlay_v0.json" "$OVERLAY_DIR/g_epf_overlay_v0.json"
          copy_if_exists "artifacts/g_epf_overlay_v0.md" "$OVERLAY_DIR/g_epf_overlay_v0.md"

      - name: Export overlay HTML summary
        shell: bash
        run: |
          set -euo pipefail
          python tools/overlay_to_html_summary.py --overlay_dir artifacts/overlay

      - name: Copy overlay HTML to report root
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          if [ ! -f artifacts/overlay/overlay_summary.html ]; then
            echo "::warning::overlay_summary.html not found at artifacts/overlay/overlay_summary.html; skipping copy."
            exit 0
          fi

          cp artifacts/overlay/overlay_summary.html artifacts/overlay_summary.html

      - name: Write status.json key-order diagnosis (for debugging)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          if [ ! -f tools/status_key_order_diagnosis.py ]; then
            echo "::warning::status_key_order_diagnosis.py not found at tools/status_key_order_diagnosis.py; skipping."
            exit 0
          fi

          python tools/status_key_order_diagnosis.py --status tests/fixtures/quick_status.json

      - name: Write separation-phase report (HTML)
        shell: bash
        run: |
          set -euo pipefail
          python tools/separation_phase_report.py --status tests/fixtures/quick_status.json

      - name: Write separation-phase report (Markdown)
        shell: bash
        run: |
          set -euo pipefail
          python tools/separation_phase_report_md.py --status tests/fixtures/quick_status.json

      - name: Write separation-phase per-gate matrix
        shell: bash
        run: |
          set -euo pipefail
          python tools/separation_phase_matrix.py --status tests/fixtures/quick_status.json

      - name: Write separation-phase per-gate matrix (MD)
        shell: bash
        run: |
          set -euo pipefail
          python tools/separation_phase_matrix_md.py --status tests/fixtures/quick_status.json

      - name: Generate separation-phase overlay for snapshot
        shell: bash
        run: |
          set -euo pipefail
          python tools/compute_separation_phase_overlay_v0.py --status tests/fixtures/quick_status.json

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # pinned
        with:
          name: pulse-report
          if-no-files-found: warn
          path: |
            artifacts/**
            badges/*.svg
            reports/junit.xml
            reports/sarif.json

  tools-tests:
    name: Tools smoke tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # pinned
        with:
          fetch-depth: 0
          persist-credentials: false

      - name: Set up Python
        uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 # pinned
        with:
          python-version: "3.11"

      - name: Install minimal Python deps
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install pyyaml

      - name: Run exporter + governance smoke tests
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import pathlib, subprocess, sys

          root = pathlib.Path(".").resolve()
          (root / "tests" / "out").mkdir(parents=True, exist_ok=True)

          # --- FIX: normalize leading indentation safely (preserve blank-line newlines) ---
          p = root / "tests" / "test_augment_status_smoke.py"
          raw = p.read_text(encoding="utf-8", errors="replace").splitlines(True)

          fixed = []
          for ln in raw:
            # Split newline off so we never accidentally drop it
            nl = ""
            if ln.endswith("\r\n"):
              nl, body = "\r\n", ln[:-2]
            elif ln.endswith("\n"):
              nl, body = "\n", ln[:-1]
            elif ln.endswith("\r"):
              nl, body = "\r", ln[:-1]
            else:
              body = ln

            # Whitespace-only line -> keep ONLY the newline (prevents "indent gluing")
            if body.strip() == "":
              fixed.append(nl)
              continue

            # Normalize only the leading indentation segment
            indent_len = len(body) - len(body.lstrip())
            indent = body[:indent_len].replace("\t", "    ")
            indent = "".join(" " if c.isspace() else c for c in indent)
            fixed.append(indent + body[indent_len:] + nl)

          p.write_text("".join(fixed), encoding="utf-8")

          # Compile to fail fast if anything is still structurally wrong
          subprocess.check_call([sys.executable, "-m", "py_compile", str(p)])

          subprocess.check_call([sys.executable, "tests/test_exporters.py"])
          subprocess.check_call([sys.executable, "tests/test_tools_governance_smoke.py"])
          subprocess.check_call([sys.executable, "tests/test_check_external_summaries_present.py"])
          subprocess.check_call([sys.executable, "tests/test_augment_status_smoke.py"])

          print("Exporter + governance smoke tests OK")
          PY
