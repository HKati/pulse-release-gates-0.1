name: PULSE CI

on:
  push:
    branches: [main]
    tags:
      - "v*"
      - "V*"
    paths-ignore:
      - "docs/**"
      - "**/*.md"
      - "badges/**"
      - "reports/**"
      - "!docs/policy/CHANGELOG.md"

  pull_request:
    branches: [main]

  workflow_dispatch:
    inputs:
      strict_external_evidence:
        description: "Require external *_summary.json evidence (fail if missing)"
        required: false
        default: "false"
        type: choice
        options:
          - "false"
          - "true"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

# Least privilege by default: this workflow must not write to the repo.
permissions:
  contents: read

jobs:
  pulse:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # pinned
        with:
          fetch-depth: 0
          persist-credentials: false

      - name: Enforce changelog for policy/spec changes
        shell: bash
        run: |
          set -euo pipefail

          # Determine diff range depending on event type.
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            BASE="${{ github.event.pull_request.base.sha }}"
            HEAD="${{ github.event.pull_request.head.sha }}"
          elif [[ "${{ github.event_name }}" == "push" ]]; then
            BASE="${{ github.event.before }}"
            HEAD="${{ github.sha }}"
          else
            echo "Skipping changelog enforcement: unsupported event '${{ github.event_name }}'."
            exit 0
          fi

          # Handle edge cases (e.g., first commit or unusual events).
          if [[ -z "${BASE}" || "${BASE}" == "0000000000000000000000000000000000000000" ]]; then
            echo "Skipping changelog enforcement: BASE SHA is empty/zero."
            exit 0
          fi

          echo "Changelog enforcement diff range: ${BASE}..${HEAD}"

          CHANGED="$(git diff --name-only "${BASE}" "${HEAD}" || true)"
          echo "${CHANGED}" | sed 's/^/changed: /' || true

          # Files that can change release-gating meaning and therefore require changelog coverage.
          SEMANTIC_PATTERN='^(pulse_gate_policy_v0\.yml|metrics/specs/|schemas/dataset_manifest\.schema\.json|examples/dataset_manifest\.example\.json)'

          # Changelog file containing semantic change notes.
          CHANGELOG_PATH='docs/policy/CHANGELOG.md'

          # If nothing semantic changed, do nothing.
          SEMANTIC_CHANGED="$(echo "${CHANGED}" | grep -E "${SEMANTIC_PATTERN}" || true)"
          if [[ -z "${SEMANTIC_CHANGED}" ]]; then
            echo "No semantic policy/spec/contract changes detected; changelog update not required."
            exit 0
          fi

          if [[ ! -f "${CHANGELOG_PATH}" ]]; then
            echo "::error::Changelog not found at ${CHANGELOG_PATH}."
            exit 1
          fi

          export SEMANTIC_CHANGED
          export CHANGELOG_PATH

          python3 - <<'PY'
          import os, re, sys
          from pathlib import Path

          changed = [ln.strip() for ln in os.environ["SEMANTIC_CHANGED"].splitlines() if ln.strip()]
          changelog_path = Path(os.environ["CHANGELOG_PATH"])
          text = changelog_path.read_text(encoding="utf-8", errors="replace")

          # Accept both "## Unreleased" and "## [Unreleased]" (robust, not brittle).
          m = re.search(r"^##\s*\[?\s*Unreleased\s*\]?\s*$([\s\S]*?)(?=^##\s+\S|\Z)", text, flags=re.M | re.I)
          if not m:
            print("::error::docs/policy/CHANGELOG.md is missing an 'Unreleased' section (expected '## Unreleased' or '## [Unreleased]').")
            sys.exit(1)

          unrel = m.group(1)
          unrel_l = unrel.lower()

          def stem_variants(stem: str):
            s = stem.lower()
            s2 = re.sub(r"_v\d+$", "", s)  # drop _v0 suffix (q3_fairness_v0 -> q3_fairness)
            return {
              s,
              s2,
              s2.replace("_", " "),
              s2.replace("_", "-"),
            }

          def parse_spec_id_version(path: Path):
            # Minimal YAML parsing for the spec block: look for top-level "spec:" then id/version inside.
            in_spec = False
            spec_id = None
            spec_ver = None

            for raw in path.read_text(encoding="utf-8", errors="replace").splitlines():
              line = raw.rstrip("\n")

              # enter spec block on exact top-level "spec:"
              if not in_spec and re.match(r"^spec:\s*$", line):
                in_spec = True
                continue

              if in_spec:
                # leaving spec block when another top-level key starts (non-empty and no leading spaces)
                if re.match(r"^[A-Za-z0-9_]+\s*:\s*$", line) and not line.startswith(" "):
                  break

                # capture id and version lines inside spec
                m_id = re.match(r"^\s*id:\s*(.+?)\s*$", line)
                if m_id and spec_id is None:
                  spec_id = m_id.group(1).strip().strip('"').strip("'")
                  continue

                m_ver = re.match(r"^\s*version:\s*(.+?)\s*$", line)
                if m_ver and spec_ver is None:
                  spec_ver = m_ver.group(1).strip().strip('"').strip("'")
                  continue

                if spec_id and spec_ver:
                  break

            return spec_id, spec_ver

          def parse_policy_id_version(path: Path):
            # Minimal YAML parsing for the policy block: look for top-level "policy:" then id/version inside.
            in_policy = False
            pol_id = None
            pol_ver = None

            for raw in path.read_text(encoding="utf-8", errors="replace").splitlines():
              line = raw.rstrip("\n")

              # enter policy block on exact top-level "policy:"
              if not in_policy and re.match(r"^policy:\s*$", line):
                in_policy = True
                continue

              if in_policy:
                # leaving policy block when another top-level key starts (non-empty and no leading spaces)
                if re.match(r"^[A-Za-z0-9_]+\s*:\s*$", line) and not line.startswith(" "):
                  break

                m_id = re.match(r"^\s*id:\s*(.+?)\s*$", line)
                if m_id and pol_id is None:
                  pol_id = m_id.group(1).strip().strip('"').strip("'")
                  continue

                m_ver = re.match(r"^\s*version:\s*(.+?)\s*$", line)
                if m_ver and pol_ver is None:
                  pol_ver = m_ver.group(1).strip().strip('"').strip("'")
                  continue

                if pol_id and pol_ver:
                  break

            return pol_id, pol_ver

          missing = []

          for p in changed:
            if p.startswith("metrics/specs/") and p.endswith(".yml"):
              spec_path = Path(p)
              if not spec_path.exists():
                missing.append((p, "spec file missing in workspace"))
                continue

              spec_id, spec_ver = parse_spec_id_version(spec_path)

              # Fallbacks: use filename stem if spec.id missing (but warn via error).
              file_stem = spec_path.stem.lower()
              want_any = set()

              if spec_id:
                want_any |= stem_variants(spec_id)
              else:
                want_any |= stem_variants(file_stem)

              # Require at least one identifier token AND the version string to appear in Unreleased.
              id_ok = any(tok and tok in unrel_l for tok in want_any)
              ver_ok = (spec_ver is not None) and (str(spec_ver).strip() in unrel)

              if not id_ok or not ver_ok:
                reason = []
                if not id_ok:
                  reason.append(f"missing id token (expected one of: {sorted(want_any)})")
                if spec_ver is None:
                  reason.append("missing spec.version in file")
                elif not ver_ok:
                  reason.append(f"missing version '{spec_ver}' in Unreleased")
                missing.append((p, "; ".join(reason)))
            elif p == "pulse_gate_policy_v0.yml":
              pol_path = Path(p)
              if not pol_path.exists():
                missing.append((p, "policy file missing in workspace"))
                continue

              pol_id, pol_ver = parse_policy_id_version(pol_path)

              if pol_id is None:
                # fallback to file stem
                pol_id = pol_path.stem
              want_any = stem_variants(pol_id)

              id_ok = any(tok and tok in unrel_l for tok in want_any)
              ver_ok = (pol_ver is not None) and (str(pol_ver).strip() in unrel)

              if not id_ok or not ver_ok:
                reason = []
                if not id_ok:
                  reason.append(f"missing policy id token (expected one of: {sorted(want_any)})")
                if pol_ver is None:
                  reason.append("missing policy.version in file")
                elif not ver_ok:
                  reason.append(f"missing version '{pol_ver}' in Unreleased")
                missing.append((p, "; ".join(reason)))
            elif p in ("schemas/dataset_manifest.schema.json", "examples/dataset_manifest.example.json"):
              key = Path(p).stem.replace(".", " ").replace("_", " ").lower()
              if key not in unrel_l:
                missing.append((p, f"missing '{key}' mention in Unreleased"))

          if missing:
            print("::error::Changelog is missing required Unreleased notes for semantic changes:")
            for p, reason in missing:
              print(f"  - {p}: {reason}")
            sys.exit(1)

          print("Changelog enforcement: OK")
          PY

      - name: Install system deps
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq

      - name: Set up Python
        uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 # pinned
        with:
          python-version: "3.11"

      - name: Install Python deps
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt

      - name: Prepare pack dir (workspace)
        shell: bash
        run: |
          set -euo pipefail

          # Ensure a stable, short workspace path for large runs.
          ROOT="$GITHUB_WORKSPACE"
          PACK_DIR="${ROOT}/PULSE_safe_pack_v0"
          echo "PACK_DIR=$PACK_DIR" >> "$GITHUB_ENV"

          if [ ! -d "$PACK_DIR" ]; then
            echo "::error::PACK_DIR not found at $PACK_DIR"
            exit 1
          fi

          echo "PACK_DIR=$PACK_DIR"

      - name: Run pack gating pipeline
        shell: bash
        run: |
          set -euo pipefail

          # Run the gating pack.
          python "${{ env.PACK_DIR }}/tools/run_all.py" \
            --pack_dir "${{ env.PACK_DIR }}" \
            --gate_policy "${{ env.PACK_DIR }}/pulse_gate_policy_v0.yml"

      - name: Show main status.json (head)
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          echo "----- status.json (head) -----"
          head -n 200 "${{ env.PACK_DIR }}/artifacts/status.json" || true
          echo "-------------------------------"

      - name: Compute external evidence list (for snapshot)
        shell: bash
        run: |
          set -euo pipefail
          STATUS="${{ env.PACK_DIR }}/artifacts/status.json"
          EXTERNAL_DIR="${{ env.PACK_DIR }}/artifacts/external"
          SCRIPT="${{ env.PACK_DIR }}/tools/external_evidence_list.py"

          if [ ! -f "$SCRIPT" ]; then
            echo "::warning::external_evidence_list.py not found at $SCRIPT; skipping."
            exit 0
          fi

          python "$SCRIPT" \
            --status "$STATUS" \
            --external_dir "$EXTERNAL_DIR"


      - name: Export top-level summary for snapshot
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/status_to_summary.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Update artifacts for snapshot
        if: always()
        shell: bash
        run: |
          set -euo pipefail

          SCRIPT="${{ env.PACK_DIR }}/tools/update_artifacts_for_snapshot.py"
          STATUS="${{ env.PACK_DIR }}/artifacts/status.json"

          if [ ! -f "$SCRIPT" ]; then
            echo "::warning::update_artifacts_for_snapshot.py not found at $SCRIPT; skipping."
            exit 0
          fi

          python "$SCRIPT" \
            --status "$STATUS"

      - name: Write separation overlay and summary
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/compute_separation_phase_overlay_v0.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Show separation-phase overlay
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          echo "----- separation_phase_overlay_v0.md -----"
          cat "${{ env.PACK_DIR }}/artifacts/separation_phase_overlay_v0.md" || true
          echo "-----------------------------------------"

      - name: Write audit-metric summary
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/audit_metric_summary.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Show audit-metric summary
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          echo "----- audit_metric_summary.json -----"
          cat "${{ env.PACK_DIR }}/artifacts/audit_metric_summary.json" || true
          echo "-------------------------------------"

      - name: Write refusal-delta summary
        shell: bash
        run: |
          set -euo pipefail

          # Read pairs from the policy (same source as pack).
          POLICY="${{ env.PACK_DIR }}/pulse_gate_policy_v0.yml"
          PAIRS="$(python "${{ env.PACK_DIR }}/tools/policy_to_refusal_pairs.py" --policy "$POLICY")"

          if [[ -z "$PAIRS" ]]; then
            echo "::warning::No refusal_delta pairs produced; skipping."
            exit 0
          fi

          RD="${{ env.PACK_DIR }}/tools/refusal_delta.py"
          if [ ! -f "$RD" ]; then
            echo "::error::refusal_delta.py not found at $RD"
            exit 1
          fi

          POL="${{ env.PACK_DIR }}/profiles/pulse_policy.yaml"
          python "$RD" \
            --pairs "$PAIRS" \
            --out "${{ env.PACK_DIR }}/artifacts/refusal_delta_summary.json" \
            --policy_config "$POL"

      - name: Show refusal-delta summary
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          echo "----- refusal_delta_summary.json -----"
          cat "${{ env.PACK_DIR }}/artifacts/refusal_delta_summary.json" || true
          echo "-------------------------------------"

      - name: "Strict external evidence: require external summaries present (pre-augment, fail-closed)"
        if: ${{ (github.event_name == 'workflow_dispatch' && github.event.inputs.strict_external_evidence == 'true') || startsWith(github.ref, 'refs/tags/v') || startsWith(github.ref, 'refs/tags/V') }}
        shell: bash
        run: |
          set -euo pipefail
          EXT_DIR="${{ env.PACK_DIR }}/artifacts/external"
          python scripts/check_external_summaries_present.py --external_dir "$EXT_DIR" --require_metric_key

      - name: Augment status (external + top-level flags)
        shell: bash
        run: |
          set -euo pipefail
          STATUS="${{ env.PACK_DIR }}/artifacts/status.json"
          THRESH="${{ env.PACK_DIR }}/profiles/external_thresholds.yaml"
          EXT_DIR="${{ env.PACK_DIR }}/artifacts/external"

          if [ ! -f "$STATUS" ]; then
            echo "::error::status.json not found at $STATUS"
            exit 1
          fi
          if [ ! -f "$THRESH" ]; then
            echo "::error::external thresholds not found at $THRESH"
            exit 1
          fi

          echo "::group::augment_status.py preflight"

          echo "PWD=$(pwd)"
          echo "GITHUB_REF=${GITHUB_REF:-}"
          echo "GITHUB_SHA=${GITHUB_SHA:-}"
          echo "GITHUB_WORKSPACE=${GITHUB_WORKSPACE:-}"
          echo "GIT_SHA=$(git rev-parse HEAD)"

          echo "STATUS=$STATUS"
          echo "THRESH=$THRESH"
          echo "EXT_DIR=$EXT_DIR"

          # Derive PACK_DIR from STATUS: <PACK_DIR>/artifacts/status.json -> <PACK_DIR>
          PACK_DIR_DERIVED="$(dirname "$(dirname "$STATUS")")"
          AUGMENT="${PACK_DIR_DERIVED}/tools/augment_status.py"

          echo "PACK_DIR_DERIVED=$PACK_DIR_DERIVED"
          echo "AUGMENT=$AUGMENT"

          if [ ! -f "$AUGMENT" ]; then
            echo "::error::augment_status.py not found at $AUGMENT"
            exit 1
          fi

          ls -la "$AUGMENT"
          wc -l "$AUGMENT"
          sha256sum "$AUGMENT"

          # Print the region where CI reports the indentation error (line ~353)
          nl -ba "$AUGMENT" | sed -n '340,370p' || true

          echo "::endgroup::"

          # Compile-check the exact file CI is about to run
          python -m py_compile "$AUGMENT"

          python "$AUGMENT" \
            --status "$STATUS" \
            --thresholds "$THRESH" \
            --external_dir "$EXT_DIR"

      - name: Gate registry sync check
        shell: bash
        run: |
          set -euo pipefail
          python tools/check_gate_registry_sync.py \
            --status "${{ env.PACK_DIR }}/artifacts/status.json" \
            --registry pulse_gate_registry_v0.yml \
            --emit-stubs

      - name: Policy ↔ registry consistency check
        shell: bash
        run: |
          set -euo pipefail

          # 1) required set must be consistent
          python tools/tools/check_policy_registry_consistency.py \
            --registry pulse_gate_registry_v0.yml \
            --policy pulse_gate_policy_v0.yml \
            --sets required

          # 2) core_required set must be consistent too (PRs enforce this set)
          python tools/tools/check_policy_registry_consistency.py \
            --registry pulse_gate_registry_v0.yml \
            --policy pulse_gate_policy_v0.yml \
            --sets core_required

          # 3) Guardrail: core_required must be a subset of required (prevents semantic drift)
          python - <<'PY'
          import sys
          import yaml

          with open("pulse_gate_policy_v0.yml", "r", encoding="utf-8") as f:
            pol = yaml.safe_load(f)

          core = set(pol["sets"]["core_required"])
          req = set(pol["sets"]["required"])

          missing = sorted(core - req)
          if missing:
            print("::error::core_required gates not present in required set:")
            for g in missing:
              print(f"  - {g}")
            sys.exit(1)

          print("Policy sets OK: core_required ⊆ required")
          PY

      - name: Compute stability map
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/compute_stability_map.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Render stability map
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/render_stability_map.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Compute field-level stability
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/field_stability.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Compute field-level gating scores
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/field_v0.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Compute EPF overlay
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/compute_epf_overlay_v0.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Generate PULSE snapshot report (HTML)
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/status_to_html_snapshot.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Generate PULSE snapshot report (Markdown)
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/status_to_md_snapshot.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Generate PULSE snapshot report (HTML)
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/status_to_html_snapshot.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Generate PULSE snapshot report (Markdown)
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/status_to_md_snapshot.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Write PULSE summary
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/write_pulse_summary.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Prepare overlay outputs
        shell: bash
        run: |
          set -euo pipefail

          # Copy the overlay artifacts to deterministic names for quick inspection.
          OVERLAY_DIR="${{ env.PACK_DIR }}/artifacts/overlay"
          mkdir -p "$OVERLAY_DIR"

          cp "${{ env.PACK_DIR }}/artifacts/stability_map_v0.json" "$OVERLAY_DIR/stability_map_v0.json"
          cp "${{ env.PACK_DIR }}/artifacts/stability_map_v0.md" "$OVERLAY_DIR/stability_map_v0.md"
          cp "${{ env.PACK_DIR }}/artifacts/stability_map_v0.svg" "$OVERLAY_DIR/stability_map_v0.svg"

          cp "${{ env.PACK_DIR }}/artifacts/field_stability_v0.json" "$OVERLAY_DIR/field_stability_v0.json"
          cp "${{ env.PACK_DIR }}/artifacts/field_stability_v0.md" "$OVERLAY_DIR/field_stability_v0.md"

          cp "${{ env.PACK_DIR }}/artifacts/field_v0.json" "$OVERLAY_DIR/field_v0.json"
          cp "${{ env.PACK_DIR }}/artifacts/field_v0.md" "$OVERLAY_DIR/field_v0.md"

          cp "${{ env.PACK_DIR }}/artifacts/g_epf_overlay_v0.json" "$OVERLAY_DIR/g_epf_overlay_v0.json"
          cp "${{ env.PACK_DIR }}/artifacts/g_epf_overlay_v0.md" "$OVERLAY_DIR/g_epf_overlay_v0.md"

      - name: Export overlay HTML summary
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/overlay_to_html_summary.py" \
            --overlay_dir "${{ env.PACK_DIR }}/artifacts/overlay"

      - name: Copy overlay HTML to report root
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          SRC="${{ env.PACK_DIR }}/artifacts/overlay/overlay_summary.html"
          DST="${{ env.PACK_DIR }}/artifacts/overlay_summary.html"

          if [ ! -f "$SRC" ]; then
            echo "::warning::overlay_summary.html not found at $SRC; skipping copy."
            exit 0
          fi

          cp "$SRC" "$DST"

  

      - name: Write status.json key-order diagnosis (for debugging)
        if: always()
        shell: bash
        run: |
          set -euo pipefail

          SCRIPT="${{ env.PACK_DIR }}/tools/status_key_order_diagnosis.py"
          STATUS="${{ env.PACK_DIR }}/artifacts/status.json"

          if [ ! -f "$SCRIPT" ]; then
            echo "::warning::status_key_order_diagnosis.py not found at $SCRIPT; skipping."
            exit 0
          fi

          python "$SCRIPT" \
            --status "$STATUS"

      - name: Write separation-phase report (HTML)
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/separation_phase_report.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Write separation-phase report (Markdown)
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/separation_phase_report_md.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Write separation-phase per-gate matrix
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/separation_phase_matrix.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Write separation-phase per-gate matrix (MD)
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/separation_phase_matrix_md.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Generate separation-phase overlay for snapshot
        shell: bash
        run: |
          set -euo pipefail
          python "${{ env.PACK_DIR }}/tools/compute_separation_phase_overlay_v0.py" \
            --status "${{ env.PACK_DIR }}/artifacts/status.json"

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # pinned
        with:
          name: pulse-report
          if-no-files-found: warn
          path: |
            ${{ env.PACK_DIR }}/artifacts/**
            badges/*.svg
            reports/junit.xml
            reports/sarif.json

  tools-tests:
    name: Tools smoke tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # pinned
        with:
          fetch-depth: 0
          persist-credentials: false

      - name: Set up Python
        uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 # pinned
        with:
          python-version: "3.11"

      - name: Install minimal Python deps
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          python -m pip install pyyaml

      - name: Run exporter + governance smoke tests
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import pathlib, subprocess, sys

          root = pathlib.Path(".").resolve()
          (root / "tests" / "out").mkdir(parents=True, exist_ok=True)

          subprocess.check_call([sys.executable, "tests/test_exporters.py"])
          subprocess.check_call([sys.executable, "tests/test_tools_governance_smoke.py"])
          subprocess.check_call([sys.executable, "tests/test_check_external_summaries_present.py"])
          print("Exporter + governance smoke tests OK")
          PY
