
# .github/workflows/pulse_pd_smoke.yml
name: PULSE-PD smoke (toy pipeline)

on:
  push:
    branches: [ main ]
    paths:
      - "pulse_pd/**"
      - ".github/workflows/pulse_pd_smoke.yml"
  pull_request:
    branches: [ main ]
    paths:
      - "pulse_pd/**"
      - ".github/workflows/pulse_pd_smoke.yml"
  workflow_dispatch: {}

# Least privilege: this workflow does not need to write to the repo or manage Actions.
permissions:
  contents: read

concurrency:
  group: pulse-pd-smoke-${{ github.ref }}
  cancel-in-progress: true

jobs:
  smoke:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    env:
      MPLBACKEND: Agg
      PYTHONPATH: .

    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          persist-credentials: false

      - name: Set up Python
        uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6.1.0
        with:
          python-version: "3.11"

      - name: Install minimal deps
        run: |
          python -m pip install --upgrade pip
          python -m pip install numpy matplotlib

      - name: HEP adapters compile/import (deps-free)
        run: |
          python -m py_compile pulse_pd/hep/export_uproot_npz.py pulse_pd/hep/export_root_npz.py
          python - <<'PY'
          import pulse_pd.hep.export_uproot_npz as u  # noqa: F401
          import pulse_pd.hep.export_root_npz as r    # noqa: F401
          print("OK: HEP adapters import + compile without uproot")
          PY

      - name: Generate toy X (with IDs)
        run: |
          python -m pulse_pd.examples.make_toy_X --out pulse_pd/examples/X_toy_ci.npz --n 2000 --seed 0

      - name: Run cut-based PD (writes artifacts)
        run: |
          python -m pulse_pd.run_cut_pd --x pulse_pd/examples/X_toy_ci.npz --theta pulse_pd/examples/theta_cuts_example.json --dims 0 1 --out pulse_pd/artifacts_ci

      - name: Export zone events (CSV)
        run: |
          python -m pulse_pd.export_zone_events --x pulse_pd/examples/X_toy_ci.npz --theta pulse_pd/examples/theta_cuts_example.json --zones pulse_pd/artifacts_ci/pd_zones_v0.jsonl --out pulse_pd/artifacts_ci/pd_zone_events_v0.csv --topn-per-zone 5 --sort-by pi_norm --ds-M 12 --mi-models 5 --gf-K 4 --seed 0

      - name: Export top PI events (CSV)
        run: |
          python -m pulse_pd.export_top_pi_events --x pulse_pd/examples/X_toy_ci.npz --theta pulse_pd/examples/theta_cuts_example.json --out pulse_pd/artifacts_ci/top_pi_events.csv --topn 50

      - name: Build CI NPZ without event_id (run/lumi/event only)
        run: |
          python - <<'PY'
          import os
          import numpy as np

          os.makedirs("pulse_pd/artifacts_ci", exist_ok=True)

          rng = np.random.default_rng(0)
          n, d = 25, 3
          X = rng.standard_normal((n, d)).astype(np.float32)

          run = np.full(n, 1, dtype=np.int64)
          lumi = np.arange(n, dtype=np.int64)
          event = np.arange(1000, 1000 + n, dtype=np.int64)

          feature_names = np.asarray([f"x{i}" for i in range(d)], dtype=object)

          np.savez(
              "pulse_pd/artifacts_ci/X_ci_no_event_id.npz",
              X=X,
              feature_names=feature_names,
              run=run,
              lumi=lumi,
              event=event,
          )
          print("Wrote pulse_pd/artifacts_ci/X_ci_no_event_id.npz")
          PY

      - name: Export top-PI events (CI NPZ without event_id)
        run: |
          python -m pulse_pd.export_top_pi_events --x pulse_pd/artifacts_ci/X_ci_no_event_id.npz --theta pulse_pd/examples/theta_cuts_example.json --out pulse_pd/artifacts_ci/top_pi_events_ci.csv --topn 10

      - name: Assert top-PI CSV has traceback columns + event_id backfill
        run: |
          python - <<'PY'
          import csv
          from pathlib import Path

          p = Path("pulse_pd/artifacts_ci/top_pi_events_ci.csv")
          assert p.exists(), f"Missing expected CSV: {p}"

          with p.open("r", encoding="utf-8", newline="") as f:
              r = csv.reader(f)
              header = next(r)

              required = ["idx", "event_id", "run", "lumi", "event"]
              for col in required:
                  assert col in header, f"Missing '{col}' in header: {header}"

              i_eid = header.index("event_id")
              i_run = header.index("run")
              i_lumi = header.index("lumi")
              i_evt = header.index("event")

              # Check first few rows for exact "run:lumi:event" backfill format
              for _ in range(5):
                  row = next(r)
                  eid = row[i_eid]
                  expected = f"{row[i_run]}:{row[i_lumi]}:{row[i_evt]}"
                  assert eid == expected, f"event_id mismatch: got {eid} expected {expected}"

          print("OK: top-PI CSV includes traceback columns and event_id backfill works")
          PY

      - name: Adapter stub smoke (CSV -> X.npz schema)
        shell: bash
        run: |
          set -euo pipefail

          # 1) Create a tiny analysis-like CSV with IDs + weights + 2 features
          python - <<'PY'
          import csv, os
          import numpy as np

          os.makedirs("pulse_pd/artifacts_ci", exist_ok=True)
          out_csv = "pulse_pd/artifacts_ci/adapter_stub_ci.csv"

          rng = np.random.default_rng(0)
          n = 200
          x0 = rng.normal(size=n)
          x1 = rng.normal(size=n)

          with open(out_csv, "w", newline="", encoding="utf-8") as f:
              w = csv.writer(f)
              w.writerow(["run", "lumi", "event", "weight", "x0", "x1"])
              for i in range(n):
                  w.writerow([1, 10, int(1000 + i), 1.0, float(x0[i]), float(x1[i])])

          print("Wrote CSV:", out_csv)
          PY

          # 2) Export to PULSEâ€“PD X.npz schema
          python -m pulse_pd.export_x_npz \
            --in-csv pulse_pd/artifacts_ci/adapter_stub_ci.csv \
            --out pulse_pd/artifacts_ci/X_adapter_stub_ci.npz \
            --require-ids \
            --make-event-id

          # 3) Validate NPZ schema keys + shapes (fail-fast)
          python - <<'PY'
          import numpy as np

          path = "pulse_pd/artifacts_ci/X_adapter_stub_ci.npz"
          z = np.load(path, allow_pickle=True)
          keys = set(z.keys())

          required = {"X", "feature_names", "run", "lumi", "event", "event_id", "weight"}
          missing = sorted(required - keys)
          if missing:
              raise SystemExit(f"Missing keys in NPZ: {missing}. Present: {sorted(keys)}")

          X = z["X"]
          if X.ndim != 2:
              raise SystemExit(f"X must be 2D; got shape {X.shape}")

          fn = z["feature_names"]
          if len(fn) != X.shape[1]:
              raise SystemExit(f"feature_names length {len(fn)} != d={X.shape[1]}")

          n = X.shape[0]
          for k in ["run", "lumi", "event", "event_id", "weight"]:
              if z[k].shape[0] != n:
                  raise SystemExit(f"{k} length mismatch: {z[k].shape[0]} != n={n}")

          print("Adapter NPZ OK:", path)
          print("Keys:", sorted(keys))
          print("Shape:", X.shape)
          PY

      - name: Validate Dropzone artifacts (schema)
        run: |
          python - <<'PY'
          import json
          from pathlib import Path

          out = Path("pulse_pd/artifacts_ci")

          # pd_run_meta.json
          meta = json.loads((out / "pd_run_meta.json").read_text(encoding="utf-8"))
          assert meta.get("schema") == "pulse_pd/pd_run_meta_v0", meta.get("schema")
          assert meta.get("tool") == "pulse_pd.run_cut_pd", meta.get("tool")
          for k in ("inputs", "params", "data", "artifacts"):
            assert k in meta, f"Missing key in pd_run_meta.json: {k}"

          # pd_peaks_v0.json
          peaks = json.loads((out / "pd_peaks_v0.json").read_text(encoding="utf-8"))
          assert peaks.get("schema") == "pulse_pd/pd_peaks_v0", peaks.get("schema")
          assert isinstance(peaks.get("peaks"), list), "peaks must be a list"

          # pd_zones_v0.jsonl (check first few lines)
          zpath = out / "pd_zones_v0.jsonl"
          lines = zpath.read_text(encoding="utf-8").splitlines()
          for line in lines[:3]:
            z = json.loads(line)
            assert z.get("schema") == "pulse_pd/pd_zone_v0", z.get("schema")
            for k in ("zone_id", "dims", "ranges", "stats"):
              assert k in z, f"Missing '{k}' in zone: {z.keys()}"

          print("OK: Dropzone artifacts parse + schema checks passed")
          PY

      - name: Assert artifacts exist
        shell: bash
        run: |
          set -euo pipefail
          test -f pulse_pd/artifacts_ci/pd_summary.json
          test -f pulse_pd/artifacts_ci/top_pi_events.csv
          test -f pulse_pd/artifacts_ci/pd_scatter.png
          test -f pulse_pd/artifacts_ci/pi_heatmap.png

          # Dropzone v0 artifacts (regression guard)
          test -f pulse_pd/artifacts_ci/pd_run_meta.json
          test -f pulse_pd/artifacts_ci/pd_zones_v0.jsonl
          test -f pulse_pd/artifacts_ci/pd_peaks_v0.json
          test -f pulse_pd/artifacts_ci/pd_zone_events_v0.csv

          echo "OK: PULSE-PD toy smoke artifacts present."

      - name: Upload artifacts (debug)
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: pulse-pd-smoke-artifacts
          if-no-files-found: warn
          path: |
            pulse_pd/artifacts_ci/**
            pulse_pd/examples/X_toy_ci.npz
